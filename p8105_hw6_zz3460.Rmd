---
title: "p8105_hw6_zz3460"
author: "Zihan Zhou"
date: "2025-11-17"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Problem 1

Set seed and load key packages.

```{r}
set.seed(2025)

library(tidyverse)
library(broom)
library(purrr)
library(readr)
```

Read in data and clean.

```{r}
homi <- read_csv("data/homicide-data.csv")

homi_clean <- homi %>%
  janitor::clean_names() %>%
  mutate(
    city_state = str_c(city, state, sep = ", "),
    disposition = str_trim(disposition),
    solved = if_else(disposition == "Closed by arrest", 1L, 0L),
    victim_age = as.numeric(victim_age),
    victim_race = str_to_title(str_trim(victim_race)),
    victim_sex = str_to_title(str_trim(victim_sex))
  ) %>%
  filter(
    !(city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL")), 
    victim_race %in% c("White", "Black")                                               
  )

glimpse(homi_clean)
count(homi_clean, city_state) %>% arrange(desc(n)) %>% head()
```

Fit a logistic regression for Baltimore.

```{r}
baltimore <- homi_clean %>% filter(city_state == "Baltimore, MD")

balt_model <- glm(solved ~ victim_age + victim_sex + victim_race, data = baltimore, family = binomial())
balt_tidy <- tidy(balt_model, conf.int = TRUE, exponentiate = TRUE)

balt_OR_row <- balt_tidy %>% filter(term == "victim_sexMale")
balt_OR_row
```

Fit models by city robustly, extract OR and CI for male vs female

```{r}
city_summary <- homi_clean %>%
  nest(data = -city_state) %>%
  mutate(
    fit = map(data, function(df) {
      glm(solved ~ victim_sex + victim_age + victim_race, 
          data = df, 
          family = binomial)
    }),
    tidied = map(fit, ~tidy(., conf.int = TRUE, exponentiate = TRUE))
  ) %>% 
  unnest(tidied) %>% 
  select(-data, -fit)

or_by_city <- city_summary %>%
  filter(term == "victim_sexMale") %>%
  select(city_state, estimate, conf.low, conf.high, p.value) %>%
  arrange(estimate)

summary(or_by_city)

knitr::kable(or_by_city)

or_by_city %>%
  mutate(city_state = fct_reorder(city_state, estimate)) %>%
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  geom_hline(yintercept = 1, color = "red", linetype = "dashed") +
  coord_flip() +
  labs(title = "Adjusted OR for Solving Homicide (Male vs Female)", x = "City", y = "Odds Ratio (Male vs Female)") +
  theme_minimal()
```

Interpretation of the Forest Plot

This forest plot displays the adjusted odds ratios (ORs) and 95% confidence intervals (CIs) for solving homicides (male vs. female victims) across cities, ordered by OR magnitude from lowest (top of the plot) to highest (bottom of the plot).

The red dashed line at OR = 1 represents the "no difference" baseline:

- Cities with ORs and CIs entirely to the left of the baseline (e.g., San Diego, CA and New York, NY) indicate female victims have statistically significantly higher odds of their homicides being solved than male victims.

- Most cities have CIs that cross the OR = 1 baseline, meaning there is no statistically significant difference in the odds of solving homicides between male and female victims in these locations.

Overall, while there is variation in ORs across cities, only a small subset show statistically significant differences in the odds of solving homicides by victim sex.

## Problem 2

Read in data and clean.

```{r}
library(p8105.datasets)
data("weather_df")
wd <- weather_df %>% select(tmax, tmin, prcp) %>% drop_na()

```

Bootstrap

```{r}
set.seed(2025)
B <- 5000
boot_results <- map_dfr(seq_len(B), function(i) {
  samp <- sample_n(wd, size = nrow(wd), replace = TRUE)
  fit <- lm(tmax ~ tmin + prcp, data = samp)
  r2 <- glance(fit)$r.squared
  td <- tidy(fit)
  beta_tmin <- td %>% filter(term == "tmin") %>% pull(estimate)
  beta_prcp <- td %>% filter(term == "prcp") %>% pull(estimate)
  tibble(r2 = r2, beta_ratio = beta_tmin / beta_prcp)
})
 
print(boot_results)
```

Distribution and CI

```{r}
ggplot(boot_results, aes(r2)) + geom_density(fill = "blue", alpha = 0.5) + labs(title = "Bootstrap distribution of R-squared")
ggplot(boot_results, aes(beta_ratio)) + geom_density(fill = "blue", alpha = 0.5) + labs(title = "Bootstrap distribution of beta1 / beta2")

```

## Bootstrap Distribution of \( R^2 \)
The bootstrap distribution for \( R^2 \) is very tightly clustered, with its peak at around 0.941. The distribution extends slightly to the left, reaching a lower bound of roughly 0.930, and tops out near 0.950 on the upper end. These uniformly high values show that the model captures about 93% to 95% of the variation in daily maximum temperature, evidence of an extremely strong and reliable fit.


## Bootstrap Distribution of \( \beta_{\text{ratio}} \)
The bootstrap distribution for \( \beta_{\text{ratio}} \) (the ratio of the \( t_{\text{min}} \) and \( \text{prcp} \) coefficients) is roughly unimodal, with a clear leftward skew and a central value of about -170. Most of the estimates lie between -100 and -300, and every value in the distribution is negative. This tells us that the two predictors act in opposite directions. The pronounced left tail arises because, in some bootstrap samples, the precipitation coefficient (the denominator of the ratio) is near zero, making the ratio large and negative.

```{r}
r2_CI <- quantile(boot_results$r2, c(0.025, 0.975))
beta_ratio_CI <- quantile(boot_results$beta_ratio, c(0.025, 0.975))

r2_CI
beta_ratio_CI
```

The 95% confidence interval for \( \beta_{\text{ratio}} \) falls between –277.8610 and –125.1789. Because this entire interval is strictly negative and does not include zero, we conclude with 95% confidence that the ratio of the coefficients is statistically significant and negative. This indicates that the two predictors consistently have effects in opposite directions (specifically, minimum temperature has a positive effect while precipitation has a negative effect).

The 95% confidence interval for \( R^2 \) ranges from 0.934 to 0.947. This narrow and high interval shows that the model is highly robust. We can be 95% confident that the predictors explain between 93.4% and 94.7% of the variation in maximum temperature, demonstrating strong and stable predictive performance.

## Problem 3

Load and clean the data.

```{r}
bw <- read_csv("data/birthweight.csv")

bw_clean <- bw %>%
  mutate(
    babysex = factor(babysex, levels = c(1,2), labels = c("male","female")),
    frace = factor(frace), mrace = factor(mrace), malform = factor(malform)
  ) %>%
  # keep rows with essential vars non-missing for modeling
  filter(!is.na(bwt), !is.na(blength), !is.na(bhead), !is.na(gaweeks))
```

