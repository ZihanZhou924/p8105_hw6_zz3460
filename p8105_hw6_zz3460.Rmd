---
title: "p8105_hw6_zz3460"
author: "Zihan Zhou"
date: "2025-11-17"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Problem 1

Set seed and load key packages.

```{r}
set.seed(2025)

library(tidyverse)
library(broom)
library(purrr)
library(readr)
```

Read in data and clean.

```{r}
homi <- read_csv("data/homicide-data.csv")

homi_clean <- homi %>%
  janitor::clean_names() %>%
  mutate(
    city_state = str_c(city, state, sep = ", "),
    disposition = str_trim(disposition),
    solved = if_else(disposition == "Closed by arrest", 1L, 0L),
    victim_age = as.numeric(victim_age),
    victim_race = str_to_title(str_trim(victim_race)),
    victim_sex = str_to_title(str_trim(victim_sex))
  ) %>%
  filter(
    !(city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL")), 
    victim_race %in% c("White", "Black")                                               
  )

glimpse(homi_clean)
count(homi_clean, city_state) %>% arrange(desc(n)) %>% head()
```

Fit a logistic regression for Baltimore.

```{r}
baltimore <- homi_clean %>% filter(city_state == "Baltimore, MD")

balt_model <- glm(solved ~ victim_age + victim_sex + victim_race, data = baltimore, family = binomial())
balt_tidy <- tidy(balt_model, conf.int = TRUE, exponentiate = TRUE)

balt_OR_row <- balt_tidy %>% filter(term == "victim_sexMale")
balt_OR_row
```

Fit models by city robustly, extract OR and CI for male vs female

```{r}
city_summary <- homi_clean %>%
  nest(data = -city_state) %>%
  mutate(
    fit = map(data, function(df) {
      glm(solved ~ victim_sex + victim_age + victim_race, 
          data = df, 
          family = binomial)
    }),
    tidied = map(fit, ~tidy(., conf.int = TRUE, exponentiate = TRUE))
  ) %>% 
  unnest(tidied) %>% 
  select(-data, -fit)

or_by_city <- city_summary %>%
  filter(term == "victim_sexMale") %>%
  select(city_state, estimate, conf.low, conf.high, p.value) %>%
  arrange(estimate)

summary(or_by_city)

knitr::kable(or_by_city)

or_by_city %>%
  mutate(city_state = fct_reorder(city_state, estimate)) %>%
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  geom_hline(yintercept = 1, color = "red", linetype = "dashed") +
  coord_flip() +
  labs(title = "Adjusted OR for Solving Homicide (Male vs Female)", x = "City", y = "Odds Ratio (Male vs Female)") +
  theme_minimal()
```

Interpretation of the Forest Plot

This forest plot displays the adjusted odds ratios (ORs) and 95% confidence intervals (CIs) for solving homicides (male vs. female victims) across cities, ordered by OR magnitude from lowest (top of the plot) to highest (bottom of the plot).

The red dashed line at OR = 1 represents the "no difference" baseline:

- Cities with ORs and CIs entirely to the left of the baseline (e.g., San Diego, CA and New York, NY) indicate female victims have statistically significantly higher odds of their homicides being solved than male victims.

- Most cities have CIs that cross the OR = 1 baseline, meaning there is no statistically significant difference in the odds of solving homicides between male and female victims in these locations.

Overall, while there is variation in ORs across cities, only a small subset show statistically significant differences in the odds of solving homicides by victim sex.

## Problem 2

Read in data and clean.

```{r}
library(p8105.datasets)
data("weather_df")
wd <- weather_df %>% select(tmax, tmin, prcp) %>% drop_na()

```

Bootstrap

```{r}
set.seed(2025)
B <- 5000
boot_results <- map_dfr(seq_len(B), function(i) {
  samp <- sample_n(wd, size = nrow(wd), replace = TRUE)
  fit <- lm(tmax ~ tmin + prcp, data = samp)
  r2 <- glance(fit)$r.squared
  td <- tidy(fit)
  beta_tmin <- td %>% filter(term == "tmin") %>% pull(estimate)
  beta_prcp <- td %>% filter(term == "prcp") %>% pull(estimate)
  tibble(r2 = r2, beta_ratio = beta_tmin / beta_prcp)
})
 
print(boot_results)
```

Distribution and CI

```{r}
ggplot(boot_results, aes(r2)) + geom_density(fill = "blue", alpha = 0.5) + labs(title = "Bootstrap distribution of R-squared")
ggplot(boot_results, aes(beta_ratio)) + geom_density(fill = "blue", alpha = 0.5) + labs(title = "Bootstrap distribution of beta1 / beta2")

```

## Bootstrap Distribution of \( R^2 \)
The bootstrap distribution for \( R^2 \) is very tightly clustered, with its peak at around 0.941. The distribution extends slightly to the left, reaching a lower bound of roughly 0.930, and tops out near 0.950 on the upper end. These uniformly high values show that the model captures about 93% to 95% of the variation in daily maximum temperature, evidence of an extremely strong and reliable fit.


## Bootstrap Distribution of \( \beta_{\text{ratio}} \)
The bootstrap distribution for \( \beta_{\text{ratio}} \) (the ratio of the \( t_{\text{min}} \) and \( \text{prcp} \) coefficients) is roughly unimodal, with a clear leftward skew and a central value of about -170. Most of the estimates lie between -100 and -300, and every value in the distribution is negative. This tells us that the two predictors act in opposite directions. The pronounced left tail arises because, in some bootstrap samples, the precipitation coefficient (the denominator of the ratio) is near zero, making the ratio large and negative.

```{r}
r2_CI <- quantile(boot_results$r2, c(0.025, 0.975))
beta_ratio_CI <- quantile(boot_results$beta_ratio, c(0.025, 0.975))

r2_CI
beta_ratio_CI
```

The 95% confidence interval for \( \beta_{\text{ratio}} \) falls between –277.8610 and –125.1789. Because this entire interval is strictly negative and does not include zero, we conclude with 95% confidence that the ratio of the coefficients is statistically significant and negative. This indicates that the two predictors consistently have effects in opposite directions (specifically, minimum temperature has a positive effect while precipitation has a negative effect).

The 95% confidence interval for \( R^2 \) ranges from 0.934 to 0.947. This narrow and high interval shows that the model is highly robust. We can be 95% confident that the predictors explain between 93.4% and 94.7% of the variation in maximum temperature, demonstrating strong and stable predictive performance.

## Problem 3

Load and clean the data.

```{r}
library(modelr)
library(rsample)
bw <- read_csv("data/birthweight.csv")

bw_clean <- bw %>%
  janitor::clean_names() %>%
  mutate(
    babysex = as.factor(babysex),
    frace = as.factor(frace),
    mrace = as.factor(mrace),
    malform = as.factor(malform)
  ) %>%
  drop_na()

glimpse(bw_clean)
```

My model

Description:

I first identified predictors based on domain knowledge—fetal growth indicators (blength, bhead, gaweeks) are directly linked to birthweight, while maternal factors (babysex, momage, ppbmi, smoken, wtgain) and demographic variables (frace, mrace) are known to influence fetal development.

Then, I chose a linear regression model with bwt as the outcome, including all selected variables to capture both fetal and maternal effects.

Since the goal was to build a comprehensive model, I did not remove any variables from my model.

```{r}
prop_model <- lm(
  bwt ~ blength + bhead + gaweeks + babysex + momage + ppbmi + smoken + wtgain + frace + mrace,
  data = bw_clean
)

summary(prop_model)

bw_aug <- bw_clean %>%
  add_predictions(prop_model) %>%
  add_residuals(prop_model)

ggplot(bw_aug, aes(x = pred, y = resid)) +
  geom_point(alpha = 0.4) +
  geom_hline(yintercept = 0, color = "red") +
  labs(
    title = "Residuals vs Fitted Values",
    x = "Fitted birthweight",
    y = "Residuals"
  )

```

The plot of model residuals against fitted values reveals that for the majority of the data (central mass), the residuals are clustered around zero, indicating that the model fits reasonably well for babies with average birthweights. However, there is some evidence of non-linearity or uncaptured variance at lower predicted birthweights, where residuals tend to be positive. This suggests the model may slightly underpredict the weight of smaller babies or that other factors are influencing low birthweight outcomes.

Comparation with two other models

```{r}
model_A <- lm(bwt ~ blength + gaweeks, data = bw_clean)

model_B <- lm(
  bwt ~ bhead * blength * babysex,
  data = bw_clean
)

set.seed(123)

cv_data <- crossv_mc(bw_clean, 100) %>%
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
  )

cv_results <- cv_data %>%
  mutate(
    fit_prop  = map(train, ~ lm(bwt ~ blength + bhead + gaweeks + babysex + momage + ppbmi + smoken + wtgain + frace + mrace, data = .x)),
    fit_A     = map(train, ~ lm(bwt ~ blength + gaweeks, data = .x)),
    fit_B     = map(train, ~ lm(bwt ~ bhead * blength * babysex, data = .x)),
    mse_prop  = map2_dbl(fit_prop, test,  ~ mean((predict(.x, .y) - .y$bwt)^2)),
    mse_A     = map2_dbl(fit_A,    test,  ~ mean((predict(.x, .y) - .y$bwt)^2)),
    mse_B     = map2_dbl(fit_B,    test,  ~ mean((predict(.x, .y) - .y$bwt)^2))
  )

cv_summary <- cv_results %>%
  summarise(
    MSE_prop = mean(mse_prop),
    MSE_A    = mean(mse_A),
    MSE_B    = mean(mse_B)
  )

cv_summary

cv_results %>% 
  select(starts_with("mse")) |> 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "mse",
    names_prefix = "mse_"
  ) |> 
  mutate(model = fct_inorder(model)) |> 
  ggplot(aes(x = model, y = mse)) + 
  geom_violin()
```

The cross-validated MSE results show that prop_model has the lowest mean MSE (75,874.16), followed by model_B (83,233.12) and model_A (109,526.6). This indicates that the custom prop_model—which includes fetal measurements, maternal characteristics, and demographic factors—has the best prediction performance.

model_A (only blength and gaweeks) performs the worst, as it lacks key predictors. model_B (with interactions between bhead, blength, and babysex) improves over model_A but is less effective than prop_model, likely because it does not account for maternal factors like smoking or BMI.

The violin plot further confirms these trends: prop_model has the tightest and lowest MSE distribution, while model_A has the widest and highest distribution.